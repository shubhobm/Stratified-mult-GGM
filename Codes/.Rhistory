library(parallel)
library(caret)
source('misc_functions.R')
source('simgen.r')
nfamily = 1e2 # number of qqfamilies
## generate X data family-wise
MAF = c(0.2,0.4,0.25,0.4,0.25)
n.block = c(6,4,30,6,4)
p = sum(n.block)
n = nfamily*4
p.causal = 20
## generate two error matrices
Kmat = matrix(c(1,0,.5,.5,
0,1,.5,.5,
.5,.5,1,.5,
.5,.5,.5,1), nrow=4,ncol=4)
mytable = matrix(c(657,20770,309704,
403,1042,9013), nrow=2)
mytable
mytable = matrix(c(657,20770,309704,
403,1042,9013), nrow=2, byrow=T)
plot(mytable[1,], col="red", lwd=2, type='l')
lines(mytable[2,], col="blue", lwd=2)
legend("topleft", c("SGL","LARN"), col=c("blue","red"), lwd=2)
plot(mytable[1,], col="red", lwd=2, type='b')
lines(mytable[2,], col="blue", lwd=2)
legend("topleft", c("SGL","LARN"), col=c("blue","red"), lwd=2)
lines(mytable[2,], col="blue", lwd=2, type='b')
plot(mytable[1,], col="red", lwd=2, type='b')
lines(mytable[2,], col="blue", lwd=2, type='b')
legend("topleft", c("SGL","LARN"), col=c("blue","red"), lwd=2)
require(fda.usc)
X = matrix(rnorm(1e4), ncol=10)
colmeans(X)
colMeans(X)
mdepth.HS(X, colMEans(X))$dep
mdepth.HS(X, colMeans(X))$dep
mdepth.HS(X, colMeans(X))
mdepth.HS(X,X)$dep
hist(mdepth.RP(X,X)$dep)
mdepth.HS(X,matrix(colMeans(X), ncol=1))$dep
mdepth.HS(colMeans(X), X)$dep
mdepth.HS(matrix(colMeans(X), ncol=1), X)$dep
mdepth.HS(matrix(colMeans(X), ncol=10), X)$dep
?aggregate\
?aggregate
?xtabs
?rbind
?regress
require(regress)
?regress
?install.packages
require(caret)
createFolds()
createFolds
loopfun = function(foldnum){
train = which(folds != foldnum)
ftrain = length(train)
train = rep(4*train, rep(4,ftrain)) - rep(c(3,2,1,0), ftrain)
Kron = kronecker(diag(ftrain), Kmat)
ntrain = length(train)
mod = regress(y~.-1, ~Kron, data=df[train,])
select.ind = step1.depth(mod, sdn, adj)
err.fold = sum(y[-train]^2)
#if(length(select.ind) > 0){
err.fold = sum((y[-train] - X[[train, select.ind] %*% mod.beta)^2)
#}
err.fold
}
require(parallel)
detectCores()
getwd()
read.csv("C:/Study/My projects/SNP-selection-twin-studies/gedi5 outputs")
read.csv("C:/Study/My projects/SNP-selection-twin-studies/gedi5 outputs/geneinfo.csv")
gene.info.df = read.csv("C:/Study/My projects/SNP-selection-twin-studies/gedi5 outputs/geneinfo.csv")
names(gene.info.df)
load("C:/Study/My projects/Depth-regression/Codes/all_results_GLt_LARN.Rda")
z = matrix(unlist(lapply(all.results, function(x) x[[5]])))
head(z)
z = matrix(unlist(lapply(all.results, function(x) x[[5]])), ncol=3, byrow=T)
head(z)
colMeans(z)
z = matrix(unlist(lapply(all.results, function(x) x[[4]])), ncol=3, byrow=T)
colMeans(z)
sqrt(colMeans(z))/(18*40)
rm(list=ls())
setwd('c:/Study/My projects/Stratified-mult-GGM/Codes')
source('jsem.R')
source('Generator.R')
source('l1LS_Main.R')
source('Objval.R')
source('JMLE.R')
library(glasso)
library(parallel)
##### Generate data
group = matrix(c(1, 2), nrow=2, ncol=2, byrow=T)           # grouping pattern
subnetSize.E = c(5, 5)
subnetSize.X = c(5, 5)    # subnet size
n = 100
p = sum(subnetSize.X)
q = sum(subnetSize.E)
K = 2
set.seed(12182017)
X.layer = GenerateLayer(n, subnetSize.X, group)
E.layer = GenerateLayer(n, subnetSize.E, group)
## generate group structure for coef array
B0.group.array = array(0, c(p,q,K))
g = 1
for(i in 1:p){
for(j in 1:q){
B0.group.array[i,j,] = g
g = g+1
}
}
B0.array = CoefArray2(B0.group.array[,,1], D=1)
# B0.array = CoefArray(B0.group.array)
B0.array = B0.array[[1]]
Diff.mat = B0.array[,,1] - B0.array[,,2]
Theta0.array = array(0, c(q,q,K))
for(k in 1:K){
Theta0.array[,,k] = with(E.layer,
diag(diag(Omega[[k]])^(-0.5)) %*% Omega[[k]] %*% diag(diag(Omega[[k]])^(-0.5)))
}
## make Y-layer
Y.layer = E.layer
for(k in 1:K){
Y.layer$data[[k]] = X.layer$data[[k]] %*% B0.array[,,k] + E.layer$data[[k]]
}
##### Given: X.list, Y.list, B.groups, Theta.groups
Y.list = lapply(Y.layer$data, as.matrix)
Y.indices = Y.layer$indices
Theta.groups = Y.layer$groups
X.list = lapply(X.layer$data, as.matrix)
Theta.group.array = array(0, c(q,q,K))
for(j in 1:q){
Theta.group.array[j,-j,] = Y.layer$groups[[j]]
}
## Obtain JMMLE fit ****************************************************
# **********************************************************************
## tune JMMLE model
lambda.vec = sqrt(log(p)/n) * seq(1, 0.2, -0.2)
model.list = vector("list", length(lambda.vec))
nlambda = length(lambda.vec)
## get all models
loopfun1 = function(m){
jmmle.1step(Y.list, Y.indices, X.list, B.group.array=B0.group.array, Theta.groups=Theta.groups,
lambda = lambda.vec[m],
gamma = sqrt(log(q)/n) * seq(1, 0.2, -0.2),
init.option=1, tol=1e-3)
}
system.time(
model.list <- lapply(1:nlambda, loopfun1)
)
## calculate HBIC
hbic.vec = rep(0, nlambda)
for(m in 1:nlambda){
jmle.model = model.list[[m]]
SSE.vec = rep(0,K)
hbic.pen.vec = rep(0,K)
for(k in 1:K){
nk = nrow(Y.list[[k]])
Theta.k = jmle.model$Theta_refit$Theta[[k]]
for(j in 1:q)
{
Theta.k[j,j] = 0
}
SSE.vec[k] = sum(diag(crossprod((Y.list[[k]] - X.list[[k]] %*%
jmle.model$B.refit[,,k]) %*% (diag(1,q) - Theta.k))))/nk
hbic.pen.vec[k] = log(log(nk))*log(q*(q-1)/2)/nk * sum(Theta.k != 0)/2 +
log(log(nk))*log(p*q)/nk * sum(jmle.model$B.refit[,,k] != 0)
}
hbic.vec[m] = sum(SSE.vec) + sum(hbic.pen.vec)
}
## select best model
jmmle.model = model.list[[which.min(hbic.vec)]]
## Tune JSEM model for X ***********************************************
# **********************************************************************
X.indices = X.layer$indices
Zeta.groups = X.layer$groups
gamma = sqrt(log(p)/n) * seq(1, 0.2, -0.2)
bic.jsem <- sel.lambda.jsem(do.call(rbind, X.list), do.call(rbind, X.list),
unlist(X.indices), unlist(X.indices),
Zeta.groups,lambda=gamma)
gamma.min = gamma[which.min(bic.jsem$BIC)]
jsem.model = JSEM(do.call(rbind, X.list), unlist(X.indices),
Zeta.groups, lambda=gamma.min)
Zeta_new.array = array(0, c(p,p,K))
for(k in 1:K){
Zeta_new.array[,,k] = jsem.model$Theta[[k]]
}
## Get debiased estimates **********************************************
# **********************************************************************
B.hat.array = jmmle.model$B.refit
C.hat.array = B.hat.array
M = matrix(0,p,K)
for(k in 1:K){
X.k = X.list[[k]]
E.k = Y.list[[k]] - X.k %*% B.hat.array[,,k]
for(i in 1:p){
R.ik = X.k[,i] - X.k[,-i] %*% Zeta_new.array[i,-i,k]
t.ik = as.numeric(t(R.ik) %*% X.k[,i]/n)
C.hat.array[i,,k] = B.hat.array[i,,k] + t(R.ik) %*% E.k/n/t.ik
M[i,k] = sqrt(n)*t.ik/sqrt(sum(R.ik^2/n))
}
}
## Get eigenvectors and eigenvalues of precision matrices
e1 = eigen(jmmle.model$Theta_refit$Omega[[1]])
P1 = e1$vectors
L1 = e1$values
e2 = eigen(jmmle.model$Theta_refit$Omega[[2]])
P2 = e2$vectors
L2 = e2$values
## Global test statistics for i-th X-variable
Omega1.sqrt = P1 %*% diag(sqrt(L1)) %*% t(P1)
Omega2.sqrt = P2 %*% diag(sqrt(L2)) %*% t(P2)
# O1.c1 = Omega1.sqrt%*%(C.hat.array[,,1])
# O2.c2 = Omega2.sqrt%*%(C.hat.array[,,2])
#
# D = rep(0,p)
# for(i in 1:p){
#   D[i] = sum((M[i,1]*O1.c1[i,] - M[i,2]*O2.c2[i,])^2)
# }
#
D = rep(0,p)
for(i in 1:p){
D[i] = sum((M[i,1]*Omega1.sqrt%*%C.hat.array[i,,1] - M[i,2]*Omega2.sqrt%*%C.hat.array[i,,2])^2)
}
which(D > qchisq(.95, 2*q)) # indices where global test is rejected
## pairwise test statistics
d = matrix(0,p,q)
for(i in 1:p){
for(j in 1:q){
d[i,] = (M[i,1]*Omega1.sqrt%*%C.hat.array[i,,1] -
M[i,2]*Omega2.sqrt%*%C.hat.array[i,,2])^2
}
}
## determine threshold for i-th test
alpha = .05
d.ind.mat = matrix(NA,p,q)
tau = rep(NA,p)
for(i in which(D > qchisq(.95, 2*q))){
tau.vec = seq(0, 20, length.out=1e2)
thres.vec = lapply(tau.vec, function(x) alpha/q * max(sum(abs(d[i,])>x),1))
thres.vec = as.numeric(thres.vec)
tau[i] = tau.vec[which.min(abs(1 - pchisq(tau.vec,2) - thres.vec))]
d.ind.mat[i,] = as.numeric(abs(d[i,])>tau[i])
}
tau.vec = seq(0, 20, length.out=1e2)
thres.vec = lapply(tau.vec, function(x) alpha/(p*q) * max(sum(d>x),1))
thres.vec = as.numeric(thres.vec)
tau = tau.vec[which.min(abs(1 - pchisq(tau.vec,2) - thres.vec))]
d.ind.mat = (d>tau)
pow = sum(d.ind.mat == 1 & Diff.mat != 0, na.rm=T)/sum(Diff.mat != 0)
size = 1 - sum(d.ind.mat == 0 & Diff.mat == 0, na.rm=T)/sum(Diff.mat == 0)
FDP = sum(d.ind.mat == 1 & Diff.mat == 0, na.rm=T)/sum(d.ind.mat == 1, na.rm=T)
c(pow,size,FDP)
Theta_new.array = array(0, c(q,q,K))
for(k in 1:K){
Theta_new.array[,,k] = jmmle.model$Theta_refit$Theta[[k]]
}
round(c(sum(B0.array != 0 & jmmle.model$B.refit != 0)/sum(B0.array != 0),
sum(B0.array == 0 & jmmle.model$B.refit == 0)/sum(B0.array == 0),
sqrt(sum((B0.array - jmmle.model$B.refit)^2)),
sum(Theta0.array != 0 & Theta_new.array != 0)/sum(Theta0.array != 0),
sum(Theta0.array == 0 & Theta_new.array == 0)/sum(Theta0.array == 0),
sqrt(sum((Theta0.array - Theta_new.array)^2))), 3)
B0.array = CoefArray2(B0.group.array[,,1], D=1, sparsity=.2)
# B0.array = CoefArray(B0.group.array)
B0.array = B0.array[[1]]
Diff.mat = B0.array[,,1] - B0.array[,,2]
Theta0.array = array(0, c(q,q,K))
for(k in 1:K){
Theta0.array[,,k] = with(E.layer,
diag(diag(Omega[[k]])^(-0.5)) %*% Omega[[k]] %*% diag(diag(Omega[[k]])^(-0.5)))
}
## make Y-layer
Y.layer = E.layer
for(k in 1:K){
Y.layer$data[[k]] = X.layer$data[[k]] %*% B0.array[,,k] + E.layer$data[[k]]
}
##### Given: X.list, Y.list, B.groups, Theta.groups
Y.list = lapply(Y.layer$data, as.matrix)
Y.indices = Y.layer$indices
Theta.groups = Y.layer$groups
X.list = lapply(X.layer$data, as.matrix)
Theta.group.array = array(0, c(q,q,K))
for(j in 1:q){
Theta.group.array[j,-j,] = Y.layer$groups[[j]]
}
## tune JMMLE model
lambda.vec = sqrt(log(p)/n) * seq(1, 0.2, -0.2)
model.list = vector("list", length(lambda.vec))
nlambda = length(lambda.vec)
## get all models
loopfun1 = function(m){
jmmle.1step(Y.list, Y.indices, X.list, B.group.array=B0.group.array, Theta.groups=Theta.groups,
lambda = lambda.vec[m],
gamma = sqrt(log(q)/n) * seq(1, 0.2, -0.2),
init.option=1, tol=1e-3)
}
system.time(
model.list <- lapply(1:nlambda, loopfun1)
)
## calculate HBIC
hbic.vec = rep(0, nlambda)
for(m in 1:nlambda){
jmle.model = model.list[[m]]
SSE.vec = rep(0,K)
hbic.pen.vec = rep(0,K)
for(k in 1:K){
nk = nrow(Y.list[[k]])
Theta.k = jmle.model$Theta_refit$Theta[[k]]
for(j in 1:q)
{
Theta.k[j,j] = 0
}
SSE.vec[k] = sum(diag(crossprod((Y.list[[k]] - X.list[[k]] %*%
jmle.model$B.refit[,,k]) %*% (diag(1,q) - Theta.k))))/nk
hbic.pen.vec[k] = log(log(nk))*log(q*(q-1)/2)/nk * sum(Theta.k != 0)/2 +
log(log(nk))*log(p*q)/nk * sum(jmle.model$B.refit[,,k] != 0)
}
hbic.vec[m] = sum(SSE.vec) + sum(hbic.pen.vec)
}
## select best model
jmmle.model = model.list[[which.min(hbic.vec)]]
## Tune JSEM model for X ***********************************************
# **********************************************************************
X.indices = X.layer$indices
Zeta.groups = X.layer$groups
gamma = sqrt(log(p)/n) * seq(1, 0.2, -0.2)
bic.jsem <- sel.lambda.jsem(do.call(rbind, X.list), do.call(rbind, X.list),
unlist(X.indices), unlist(X.indices),
Zeta.groups,lambda=gamma)
gamma.min = gamma[which.min(bic.jsem$BIC)]
jsem.model = JSEM(do.call(rbind, X.list), unlist(X.indices),
Zeta.groups, lambda=gamma.min)
Zeta_new.array = array(0, c(p,p,K))
for(k in 1:K){
Zeta_new.array[,,k] = jsem.model$Theta[[k]]
}
## Get debiased estimates **********************************************
# **********************************************************************
B.hat.array = jmmle.model$B.refit
C.hat.array = B.hat.array
M = matrix(0,p,K)
for(k in 1:K){
X.k = X.list[[k]]
E.k = Y.list[[k]] - X.k %*% B.hat.array[,,k]
for(i in 1:p){
R.ik = X.k[,i] - X.k[,-i] %*% Zeta_new.array[i,-i,k]
t.ik = as.numeric(t(R.ik) %*% X.k[,i]/n)
C.hat.array[i,,k] = B.hat.array[i,,k] + t(R.ik) %*% E.k/n/t.ik
M[i,k] = sqrt(n)*t.ik/sqrt(sum(R.ik^2/n))
}
}
## Get eigenvectors and eigenvalues of precision matrices
e1 = eigen(jmmle.model$Theta_refit$Omega[[1]])
P1 = e1$vectors
L1 = e1$values
e2 = eigen(jmmle.model$Theta_refit$Omega[[2]])
P2 = e2$vectors
L2 = e2$values
## Global test statistics for i-th X-variable
Omega1.sqrt = P1 %*% diag(sqrt(L1)) %*% t(P1)
Omega2.sqrt = P2 %*% diag(sqrt(L2)) %*% t(P2)
# O1.c1 = Omega1.sqrt%*%(C.hat.array[,,1])
# O2.c2 = Omega2.sqrt%*%(C.hat.array[,,2])
#
# D = rep(0,p)
# for(i in 1:p){
#   D[i] = sum((M[i,1]*O1.c1[i,] - M[i,2]*O2.c2[i,])^2)
# }
#
D = rep(0,p)
for(i in 1:p){
D[i] = sum((M[i,1]*Omega1.sqrt%*%C.hat.array[i,,1] - M[i,2]*Omega2.sqrt%*%C.hat.array[i,,2])^2)
}
which(D > qchisq(.95, 2*q)) # indices where global test is rejected
## pairwise test statistics
d = matrix(0,p,q)
for(i in 1:p){
for(j in 1:q){
d[i,] = (M[i,1]*Omega1.sqrt%*%C.hat.array[i,,1] -
M[i,2]*Omega2.sqrt%*%C.hat.array[i,,2])^2
}
}
## determine threshold for i-th test
alpha = .05
d.ind.mat = matrix(NA,p,q)
tau = rep(NA,p)
for(i in which(D > qchisq(.95, 2*q))){
tau.vec = seq(0, 20, length.out=1e2)
thres.vec = lapply(tau.vec, function(x) alpha/q * max(sum(abs(d[i,])>x),1))
thres.vec = as.numeric(thres.vec)
tau[i] = tau.vec[which.min(abs(1 - pchisq(tau.vec,2) - thres.vec))]
d.ind.mat[i,] = as.numeric(abs(d[i,])>tau[i])
}
tau.vec = seq(0, 20, length.out=1e2)
thres.vec = lapply(tau.vec, function(x) alpha/(p*q) * max(sum(d>x),1))
thres.vec = as.numeric(thres.vec)
tau = tau.vec[which.min(abs(1 - pchisq(tau.vec,2) - thres.vec))]
d.ind.mat = (d>tau)
pow = sum(d.ind.mat == 1 & Diff.mat != 0, na.rm=T)/sum(Diff.mat != 0)
size = 1 - sum(d.ind.mat == 0 & Diff.mat == 0, na.rm=T)/sum(Diff.mat == 0)
FDP = sum(d.ind.mat == 1 & Diff.mat == 0, na.rm=T)/sum(d.ind.mat == 1, na.rm=T)
c(pow,size,FDP)
Theta_new.array = array(0, c(q,q,K))
for(k in 1:K){
Theta_new.array[,,k] = jmmle.model$Theta_refit$Theta[[k]]
}
round(c(sum(B0.array != 0 & jmmle.model$B.refit != 0)/sum(B0.array != 0),
sum(B0.array == 0 & jmmle.model$B.refit == 0)/sum(B0.array == 0),
sqrt(sum((B0.array - jmmle.model$B.refit)^2)),
sum(Theta0.array != 0 & Theta_new.array != 0)/sum(Theta0.array != 0),
sum(Theta0.array == 0 & Theta_new.array == 0)/sum(Theta0.array == 0),
sqrt(sum((Theta0.array - Theta_new.array)^2))), 3)
d
View(d)
View(round(d,1)
)
tau
View(B0.array[,,1])
View(Diff.mat)
d.ind.mat
d.ind.mat = as.numeric(d>tau, nrow=p, byrow=T)
d.ind.mat
d.ind.mat = as.matrix(d>tau, nrow=p, byrow=T)
d.ind.mat
d.ind.mat = as.matrix(as.numeric(d>tau), nrow=p, byrow=T)
d.ind.mat
d.ind.mat = as.matrix(as.numeric(d>tau), nrow=p, ncol=q, byrow=T)
d.ind.mat
p
q
d.ind.mat = matrix(as.numeric(d>tau), nrow=p, ncol=q, byrow=T)
d.ind.mat
d.ind.mat = matrix(as.numeric(d>tau), nrow=p, ncol=q, byrow=F)
d.ind.mat
Diff.mat
