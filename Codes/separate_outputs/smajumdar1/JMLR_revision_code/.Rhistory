eval.mat[,2] = round(bic.vec,4)
for(m in 1:length(lambda.vec)){
model.m = model.list[[m]]
for(k in 1:K){
Theta_new.array[,,k] = model.m$Theta_refit$Theta[[k]]
}
eval.mat[m,-(1:2)] = round(c(sum(B0.array != 0 & model.m$B.refit != 0)/sum(B0.array != 0),
sum(B0.array == 0 & model.m$B.refit == 0)/sum(B0.array == 0),
sqrt(sum((B0.array - model.m$B.refit)^2)/sum(B0.array^2)),
sum(Theta0.array != 0 & Theta_new.array != 0)/sum(Theta0.array != 0),
sum(Theta0.array == 0 & Theta_new.array == 0)/sum(Theta0.array == 0),
sqrt(sum((Theta0.array - Theta_new.array)^2)/sum(Theta0.array^2))), 3)
}
eval.mat = data.frame(eval.mat)
names(eval.mat) = c("lambda","BIC","B.TP","B.TN","B.rel.Fnorm","Theta.TP","Theta.TN","Theta.rel.Fnorm")
eval.mat
bic.vec = rep(0, nlambda)
for(m in 1:nlambda){
jmle.model = model.list[[m]]
jmle.bic.vec = rep(0,K)
for(k in 1:K){
nk = nrow(Y.list[[k]])
Theta.k = jmle.model$Theta_refit$Theta[[k]]
for(j in 1:q)
{
Theta.k[j,j] = 0
}
jmle.bic.vec[k] = sum(diag(crossprod((Y.list[[k]] - X.list[[k]] %*%
jmle.model$B.refit[,,k]) %*% (diag(1,q) - Theta.k))))/nk +
# log(nk)/nk * (sum(Theta.k != 0)/2 + sum(jmle.model$B.refit[,,k] != 0))
sqrt(2*log(q)/nk) * sum(Theta.k != 0)/2 + sqrt(log(p*q)/nk) * sum(jmle.model$B.refit[,,k] != 0)
}
bic.vec[m] = sum(jmle.bic.vec)
}
## all model evaluations
Theta_new.array = array(0, c(q,q,K))
eval.mat = matrix(0, ncol=8, nrow=nlambda)
eval.mat[,1] = round(lambda.vec,4)
eval.mat[,2] = round(bic.vec,4)
for(m in 1:length(lambda.vec)){
model.m = model.list[[m]]
for(k in 1:K){
Theta_new.array[,,k] = model.m$Theta_refit$Theta[[k]]
}
eval.mat[m,-(1:2)] = round(c(sum(B0.array != 0 & model.m$B.refit != 0)/sum(B0.array != 0),
sum(B0.array == 0 & model.m$B.refit == 0)/sum(B0.array == 0),
sqrt(sum((B0.array - model.m$B.refit)^2)/sum(B0.array^2)),
sum(Theta0.array != 0 & Theta_new.array != 0)/sum(Theta0.array != 0),
sum(Theta0.array == 0 & Theta_new.array == 0)/sum(Theta0.array == 0),
sqrt(sum((Theta0.array - Theta_new.array)^2)/sum(Theta0.array^2))), 3)
}
eval.mat = data.frame(eval.mat)
names(eval.mat) = c("lambda","BIC","B.TP","B.TN","B.rel.Fnorm","Theta.TP","Theta.TN","Theta.rel.Fnorm")
eval.mat
sqrt(2*log(q)/nk)
log(log(nk))*log(q)/nk
log(nk)/nk
sqrt(2*log(q)/nk)
log(log(nk))*log(p*q)/nk
bic.vec = rep(0, nlambda)
for(m in 1:nlambda){
jmle.model = model.list[[m]]
jmle.bic.vec = rep(0,K)
for(k in 1:K){
nk = nrow(Y.list[[k]])
Theta.k = jmle.model$Theta_refit$Theta[[k]]
for(j in 1:q)
{
Theta.k[j,j] = 0
}
jmle.bic.vec[k] = sum(diag(crossprod((Y.list[[k]] - X.list[[k]] %*%
jmle.model$B.refit[,,k]) %*% (diag(1,q) - Theta.k))))/nk +
# log(nk)/nk * (sum(Theta.k != 0)/2 + sum(jmle.model$B.refit[,,k] != 0))
log(log(nk))*log(q)/nk * sum(Theta.k != 0)/2 + log(log(nk))*log(p*q)/nk * sum(jmle.model$B.refit[,,k] != 0)
}
bic.vec[m] = sum(jmle.bic.vec)
}
## all model evaluations
Theta_new.array = array(0, c(q,q,K))
eval.mat = matrix(0, ncol=8, nrow=nlambda)
eval.mat[,1] = round(lambda.vec,4)
eval.mat[,2] = round(bic.vec,4)
for(m in 1:length(lambda.vec)){
model.m = model.list[[m]]
for(k in 1:K){
Theta_new.array[,,k] = model.m$Theta_refit$Theta[[k]]
}
eval.mat[m,-(1:2)] = round(c(sum(B0.array != 0 & model.m$B.refit != 0)/sum(B0.array != 0),
sum(B0.array == 0 & model.m$B.refit == 0)/sum(B0.array == 0),
sqrt(sum((B0.array - model.m$B.refit)^2)/sum(B0.array^2)),
sum(Theta0.array != 0 & Theta_new.array != 0)/sum(Theta0.array != 0),
sum(Theta0.array == 0 & Theta_new.array == 0)/sum(Theta0.array == 0),
sqrt(sum((Theta0.array - Theta_new.array)^2)/sum(Theta0.array^2))), 3)
}
eval.mat = data.frame(eval.mat)
names(eval.mat) = c("lambda","BIC","B.TP","B.TN","B.rel.Fnorm","Theta.TP","Theta.TN","Theta.rel.Fnorm")
eval.mat
## tune JMLE model
lambda.vec = sqrt(log(p*q)/nk/K) * seq(0.8, 0.1, -0.1)
nlambda = length(lambda.vec)
## get all models
loopfun1 = function(m){
jmle(Y.list, Y.indices, X.list, B.group.array=B0.group.array, Theta.groups=Theta.groups,
lambda = lambda.vec[m],
gamma = sqrt(log(p*q)/nk/K) * seq(0.8, 0.1, -0.1),
init.option=1, tol=1e-3)
}
model.list <- lapply(1:nlambda, loopfun1)
bic.vec = rep(0, nlambda)
for(m in 1:nlambda){
jmle.model = model.list[[m]]
jmle.bic.vec = rep(0,K)
for(k in 1:K){
nk = nrow(Y.list[[k]])
Theta.k = jmle.model$Theta_refit$Theta[[k]]
for(j in 1:q)
{
Theta.k[j,j] = 0
}
jmle.bic.vec[k] = sum(diag(crossprod((Y.list[[k]] - X.list[[k]] %*%
jmle.model$B.refit[,,k]) %*% (diag(1,q) - Theta.k))))/nk +
# log(nk)/nk * (sum(Theta.k != 0)/2 + sum(jmle.model$B.refit[,,k] != 0))
log(log(nk))*log(q)/nk * sum(Theta.k != 0)/2 + log(log(nk))*log(p*q)/nk * sum(jmle.model$B.refit[,,k] != 0)
}
bic.vec[m] = sum(jmle.bic.vec)
}
## all model evaluations
Theta_new.array = array(0, c(q,q,K))
eval.mat = matrix(0, ncol=8, nrow=nlambda)
eval.mat[,1] = round(lambda.vec,4)
eval.mat[,2] = round(bic.vec,4)
for(m in 1:length(lambda.vec)){
model.m = model.list[[m]]
for(k in 1:K){
Theta_new.array[,,k] = model.m$Theta_refit$Theta[[k]]
}
eval.mat[m,-(1:2)] = round(c(sum(B0.array != 0 & model.m$B.refit != 0)/sum(B0.array != 0),
sum(B0.array == 0 & model.m$B.refit == 0)/sum(B0.array == 0),
sqrt(sum((B0.array - model.m$B.refit)^2)/sum(B0.array^2)),
sum(Theta0.array != 0 & Theta_new.array != 0)/sum(Theta0.array != 0),
sum(Theta0.array == 0 & Theta_new.array == 0)/sum(Theta0.array == 0),
sqrt(sum((Theta0.array - Theta_new.array)^2)/sum(Theta0.array^2))), 3)
}
eval.mat = data.frame(eval.mat)
names(eval.mat) = c("lambda","BIC","B.TP","B.TN","B.rel.Fnorm","Theta.TP","Theta.TN","Theta.rel.Fnorm")
eval.mat
bic.vec = rep(0, nlambda)
for(m in 1:nlambda){
jmle.model = model.list[[m]]
jmle.bic.vec = rep(0,K)
for(k in 1:K){
nk = nrow(Y.list[[k]])
Theta.k = jmle.model$Theta_refit$Theta[[k]]
for(j in 1:q)
{
Theta.k[j,j] = 0
}
jmle.bic.vec[k] = sum(diag(crossprod((Y.list[[k]] - X.list[[k]] %*%
jmle.model$B.refit[,,k]) %*% (diag(1,q) - Theta.k))))/nk +
# log(nk)/nk * (sum(Theta.k != 0)/2 + sum(jmle.model$B.refit[,,k] != 0))
log(log(nk))*log(q*(q-1)/2)/nk * sum(Theta.k != 0)/2 +
log(log(nk))*log(p*q)/nk * sum(jmle.model$B.refit[,,k] != 0)
}
bic.vec[m] = sum(jmle.bic.vec)
}
## all model evaluations
Theta_new.array = array(0, c(q,q,K))
eval.mat = matrix(0, ncol=8, nrow=nlambda)
eval.mat[,1] = round(lambda.vec,4)
eval.mat[,2] = round(bic.vec,4)
for(m in 1:length(lambda.vec)){
model.m = model.list[[m]]
for(k in 1:K){
Theta_new.array[,,k] = model.m$Theta_refit$Theta[[k]]
}
eval.mat[m,-(1:2)] = round(c(sum(B0.array != 0 & model.m$B.refit != 0)/sum(B0.array != 0),
sum(B0.array == 0 & model.m$B.refit == 0)/sum(B0.array == 0),
sqrt(sum((B0.array - model.m$B.refit)^2)/sum(B0.array^2)),
sum(Theta0.array != 0 & Theta_new.array != 0)/sum(Theta0.array != 0),
sum(Theta0.array == 0 & Theta_new.array == 0)/sum(Theta0.array == 0),
sqrt(sum((Theta0.array - Theta_new.array)^2)/sum(Theta0.array^2))), 3)
}
eval.mat = data.frame(eval.mat)
names(eval.mat) = c("lambda","BIC","B.TP","B.TN","B.rel.Fnorm","Theta.TP","Theta.TN","Theta.rel.Fnorm")
eval.mat
lambda.vec = sqrt(log(p)/n) * seq(0.8, 0.1, -0.1)
nlambda = length(lambda.vec)
## get all models
loopfun1 = function(m){
jmle(Y.list, Y.indices, X.list, B.group.array=B0.group.array, Theta.groups=Theta.groups,
lambda = lambda.vec[m],
gamma = sqrt(log(q)/n) * seq(0.8, 0.1, -0.1),
init.option=1, tol=1e-3)
}
model.list <- lapply(1:nlambda, loopfun1)
bic.vec = rep(0, nlambda)
for(m in 1:nlambda){
jmle.model = model.list[[m]]
jmle.bic.vec = rep(0,K)
for(k in 1:K){
nk = nrow(Y.list[[k]])
Theta.k = jmle.model$Theta_refit$Theta[[k]]
for(j in 1:q)
{
Theta.k[j,j] = 0
}
jmle.bic.vec[k] = sum(diag(crossprod((Y.list[[k]] - X.list[[k]] %*%
jmle.model$B.refit[,,k]) %*% (diag(1,q) - Theta.k))))/nk +
# log(nk)/nk * (sum(Theta.k != 0)/2 + sum(jmle.model$B.refit[,,k] != 0))
log(log(nk))*log(q*(q-1)/2)/nk * sum(Theta.k != 0)/2 +
log(log(nk))*log(p*q)/nk * sum(jmle.model$B.refit[,,k] != 0)
}
bic.vec[m] = sum(jmle.bic.vec)
}
## all model evaluations
Theta_new.array = array(0, c(q,q,K))
eval.mat = matrix(0, ncol=8, nrow=nlambda)
eval.mat[,1] = round(lambda.vec,4)
eval.mat[,2] = round(bic.vec,4)
for(m in 1:length(lambda.vec)){
model.m = model.list[[m]]
for(k in 1:K){
Theta_new.array[,,k] = model.m$Theta_refit$Theta[[k]]
}
eval.mat[m,-(1:2)] = round(c(sum(B0.array != 0 & model.m$B.refit != 0)/sum(B0.array != 0),
sum(B0.array == 0 & model.m$B.refit == 0)/sum(B0.array == 0),
sqrt(sum((B0.array - model.m$B.refit)^2)/sum(B0.array^2)),
sum(Theta0.array != 0 & Theta_new.array != 0)/sum(Theta0.array != 0),
sum(Theta0.array == 0 & Theta_new.array == 0)/sum(Theta0.array == 0),
sqrt(sum((Theta0.array - Theta_new.array)^2)/sum(Theta0.array^2))), 3)
}
eval.mat = data.frame(eval.mat)
names(eval.mat) = c("lambda","BIC","B.TP","B.TN","B.rel.Fnorm","Theta.TP","Theta.TN","Theta.rel.Fnorm")
eval.mat
bic.vec = rep(0, nlambda)
for(m in 1:nlambda){
jmle.model = model.list[[m]]
jmle.bic.vec = rep(0,K)
for(k in 1:K){
nk = nrow(Y.list[[k]])
Theta.k = jmle.model$Theta_refit$Theta[[k]]
for(j in 1:q)
{
Theta.k[j,j] = 0
}
jmle.bic.vec[k] = sum(diag(crossprod((Y.list[[k]] - X.list[[k]] %*%
jmle.model$B.refit[,,k]) %*% (diag(1,q) - Theta.k))))/nk +
log(nk)/nk * (sum(Theta.k != 0)/2 + sum(jmle.model$B.refit[,,k] != 0))
# log(log(nk))*log(q*(q-1)/2)/nk * sum(Theta.k != 0)/2 +
# log(log(nk))*log(p*q)/nk * sum(jmle.model$B.refit[,,k] != 0)
}
bic.vec[m] = sum(jmle.bic.vec)
}
## all model evaluations
Theta_new.array = array(0, c(q,q,K))
eval.mat = matrix(0, ncol=8, nrow=nlambda)
eval.mat[,1] = round(lambda.vec,4)
eval.mat[,2] = round(bic.vec,4)
for(m in 1:length(lambda.vec)){
model.m = model.list[[m]]
for(k in 1:K){
Theta_new.array[,,k] = model.m$Theta_refit$Theta[[k]]
}
eval.mat[m,-(1:2)] = round(c(sum(B0.array != 0 & model.m$B.refit != 0)/sum(B0.array != 0),
sum(B0.array == 0 & model.m$B.refit == 0)/sum(B0.array == 0),
sqrt(sum((B0.array - model.m$B.refit)^2)/sum(B0.array^2)),
sum(Theta0.array != 0 & Theta_new.array != 0)/sum(Theta0.array != 0),
sum(Theta0.array == 0 & Theta_new.array == 0)/sum(Theta0.array == 0),
sqrt(sum((Theta0.array - Theta_new.array)^2)/sum(Theta0.array^2))), 3)
}
eval.mat = data.frame(eval.mat)
names(eval.mat) = c("lambda","BIC","B.TP","B.TN","B.rel.Fnorm","Theta.TP","Theta.TN","Theta.rel.Fnorm")
eval.mat
eval.list
load("D:/Study/My projects/Stratified-mult-GGM/Codes/out_n100p30q60k5_sep.Rda")
eval.list
class(eval.list[[1]])
?rem
5%%2
## loop over tuning parameter grid
loopfun1 = function(m3){
m1 = floor((m3-1)/nrho) + 1
m2 = m1 %% nrho
## get estimates
for(k in 1:K){
model.k = l1ML_Main(Y.list[[k]], X.list[[k]],
lambda=lambda.vec[m1], rho=rho.vec[m2],
initializer="Lasso", StabilizeTheta=TRUE)
B_sep.array[,,k] = model.k$B.est
Theta_sep.array[,,k] = model.k$Theta.est
}
## calculate BIC
bic.vec = rep(0, K)
for(k in 1:K){
nk = nrow(Y.list[[k]])
B.k = B_sep.array[,,k]
Theta.k = Theta_sep.array[,,k]
bic.vec[k] = -log(det(Theta.k)) +
sum(diag(crossprod(Y.list[[k]] - X.list[[k]] %*% B.k) %*% Theta.k))/nk +
log(nk)/nk * ((sum(Theta.k != 0)-q)/2 + sum(B.k != 0))
}
## return
c(lambda.vec[m1], rho.vec[m2], sum(bic.vec),
round(c(sum(B0.array != 0 & B_sep.array != 0)/sum(B0.array != 0),
sum(B0.array == 0 & B_sep.array == 0)/sum(B0.array == 0),
sqrt(sum((B0.array - B_sep.array)^2)/sum(B0.array^2)),
sum(Theta0.array != 0 & Theta_sep.array != 0)/sum(Theta0.array != 0),
sum(Theta0.array == 0 & Theta_sep.array == 0)/sum(Theta0.array == 0),
sqrt(sum((Theta0.array - Theta_sep.array)^2)/sum(Theta0.array^2))), 3))
}
eval.mat1 = lapply(1:nlambda*nrho, loopfun1)
rm(list=ls())
# setwd('D:/Study/My projects/Stratified-mult-GGM/Codes/')
setwd('JMLR_revision_code')
source('l1ML_Main.R')
source('../Generator.R')
source('../jsem.R')
library(parallel)
##### Generate data
group = rbind(
c(1, 2),
c(1, 4),
c(3, 2),
c(3, 4),
c(5, 2)
)                         # grouping pattern
subnetSize.E = c(30, 30)
subnetSize.X = c(15, 15)    # subnet size
n = 100
p = sum(subnetSize.X)
q = sum(subnetSize.E)
K = 5
set.seed(11192017)
set.seed(rep*11222017)
X.layer = GenerateLayer(n, subnetSize.X, group)
E.layer = GenerateLayer(n, subnetSize.E, group)
## generate group structure for coef array
B0.group.array = array(0, c(p,q,K))
g = 1
for(i in 1:p){
for(j in 1:q){
B0.group.array[i,j,] = g
g = g+1
}
}
B0.array = CoefArray(B0.group.array)
Theta0.array = array(0, c(q,q,K))
for(k in 1:K){
Theta0.array[,,k] = with(E.layer,
diag(diag(Omega[[k]])^(-0.5)) %*% Omega[[k]] %*% diag(diag(Omega[[k]])^(-0.5)))
}
## make Y-layer
Y.layer = E.layer
for(k in 1:K){
Y.layer$data[[k]] = X.layer$data[[k]] %*% B0.array[,,k] + E.layer$data[[k]]
}
##### Given: X.list, Y.list, B.groups, Theta.groups
Y.list = lapply(Y.layer$data, as.matrix)
Y.indices = Y.layer$indices
Theta.groups = Y.layer$groups
X.list = lapply(X.layer$data, as.matrix)
Theta.group.array = array(0, c(q,q,K))
for(j in 1:q){
Theta.group.array[j,-j,] = Y.layer$groups[[j]]
}
rep=1
set.seed(rep*11222017)
X.layer = GenerateLayer(n, subnetSize.X, group)
E.layer = GenerateLayer(n, subnetSize.E, group)
## generate group structure for coef array
B0.group.array = array(0, c(p,q,K))
g = 1
for(i in 1:p){
for(j in 1:q){
B0.group.array[i,j,] = g
g = g+1
}
}
B0.array = CoefArray(B0.group.array)
Theta0.array = array(0, c(q,q,K))
for(k in 1:K){
Theta0.array[,,k] = with(E.layer,
diag(diag(Omega[[k]])^(-0.5)) %*% Omega[[k]] %*% diag(diag(Omega[[k]])^(-0.5)))
}
## make Y-layer
Y.layer = E.layer
for(k in 1:K){
Y.layer$data[[k]] = X.layer$data[[k]] %*% B0.array[,,k] + E.layer$data[[k]]
}
##### Given: X.list, Y.list, B.groups, Theta.groups
Y.list = lapply(Y.layer$data, as.matrix)
Y.indices = Y.layer$indices
Theta.groups = Y.layer$groups
X.list = lapply(X.layer$data, as.matrix)
Theta.group.array = array(0, c(q,q,K))
for(j in 1:q){
Theta.group.array[j,-j,] = Y.layer$groups[[j]]
}
B_sep.array = array(0, c(p,q,K))
Theta_sep.array = array(0, c(q,q,K))
lambda.vec = sqrt(log(p)/n)*seq(1,0.2,-0.2)
rho.vec = sqrt(log(q)/n)*seq(1,0.2,-0.2)
nlambda = length(lambda.vec)
nrho = length(rho.vec)
eval.mat = matrix(0, ncol=9, nrow=nlambda*nrho)
m3 = 0
## loop over tuning parameter grid
loopfun1 = function(m3){
m1 = floor((m3-1)/nrho) + 1
m2 = m1 %% nrho
## get estimates
for(k in 1:K){
model.k = l1ML_Main(Y.list[[k]], X.list[[k]],
lambda=lambda.vec[m1], rho=rho.vec[m2],
initializer="Lasso", StabilizeTheta=TRUE)
B_sep.array[,,k] = model.k$B.est
Theta_sep.array[,,k] = model.k$Theta.est
}
## calculate BIC
bic.vec = rep(0, K)
for(k in 1:K){
nk = nrow(Y.list[[k]])
B.k = B_sep.array[,,k]
Theta.k = Theta_sep.array[,,k]
bic.vec[k] = -log(det(Theta.k)) +
sum(diag(crossprod(Y.list[[k]] - X.list[[k]] %*% B.k) %*% Theta.k))/nk +
log(nk)/nk * ((sum(Theta.k != 0)-q)/2 + sum(B.k != 0))
}
## return
c(lambda.vec[m1], rho.vec[m2], sum(bic.vec),
round(c(sum(B0.array != 0 & B_sep.array != 0)/sum(B0.array != 0),
sum(B0.array == 0 & B_sep.array == 0)/sum(B0.array == 0),
sqrt(sum((B0.array - B_sep.array)^2)/sum(B0.array^2)),
sum(Theta0.array != 0 & Theta_sep.array != 0)/sum(Theta0.array != 0),
sum(Theta0.array == 0 & Theta_sep.array == 0)/sum(Theta0.array == 0),
sqrt(sum((Theta0.array - Theta_sep.array)^2)/sum(Theta0.array^2))), 3))
}
eval.mat1 = lapply(1:nlambda*nrho, loopfun1)
cat("Done- lambda=",lambda.vec[m1],"rho=",rho.vec[m2])
## loop over tuning parameter grid
loopfun1 = function(m3){
m1 = floor((m3-1)/nrho) + 1
m2 = m1 %% nrho
## get estimates
for(k in 1:K){
model.k = l1ML_Main(Y.list[[k]], X.list[[k]],
lambda=lambda.vec[m1], rho=rho.vec[m2],
initializer="Lasso", StabilizeTheta=TRUE)
B_sep.array[,,k] = model.k$B.est
Theta_sep.array[,,k] = model.k$Theta.est
}
## calculate BIC
bic.vec = rep(0, K)
for(k in 1:K){
nk = nrow(Y.list[[k]])
B.k = B_sep.array[,,k]
Theta.k = Theta_sep.array[,,k]
bic.vec[k] = -log(det(Theta.k)) +
sum(diag(crossprod(Y.list[[k]] - X.list[[k]] %*% B.k) %*% Theta.k))/nk +
log(nk)/nk * ((sum(Theta.k != 0)-q)/2 + sum(B.k != 0))
}
## return
cat("Done- lambda=",lambda.vec[m1],"rho=",rho.vec[m2])
c(lambda.vec[m1], rho.vec[m2], sum(bic.vec),
round(c(sum(B0.array != 0 & B_sep.array != 0)/sum(B0.array != 0),
sum(B0.array == 0 & B_sep.array == 0)/sum(B0.array == 0),
sqrt(sum((B0.array - B_sep.array)^2)/sum(B0.array^2)),
sum(Theta0.array != 0 & Theta_sep.array != 0)/sum(Theta0.array != 0),
sum(Theta0.array == 0 & Theta_sep.array == 0)/sum(Theta0.array == 0),
sqrt(sum((Theta0.array - Theta_sep.array)^2)/sum(Theta0.array^2))), 3))
}
eval.mat1 = lapply(1:nlambda*nrho, loopfun1)
## loop over tuning parameter grid
loopfun1 = function(m3){
m1 = floor((m3-1)/nrho) + 1
m2 = m1 %% nrho
## get estimates
for(k in 1:K){
model.k = l1ML_Main(Y.list[[k]], X.list[[k]],
lambda=lambda.vec[m1], rho=rho.vec[m2],
initializer="Lasso", StabilizeTheta=F)
B_sep.array[,,k] = model.k$B.est
Theta_sep.array[,,k] = model.k$Theta.est
}
## calculate BIC
bic.vec = rep(0, K)
for(k in 1:K){
nk = nrow(Y.list[[k]])
B.k = B_sep.array[,,k]
Theta.k = Theta_sep.array[,,k]
bic.vec[k] = -log(det(Theta.k)) +
sum(diag(crossprod(Y.list[[k]] - X.list[[k]] %*% B.k) %*% Theta.k))/nk +
log(nk)/nk * ((sum(Theta.k != 0)-q)/2 + sum(B.k != 0))
}
## return
cat("Done- lambda=",lambda.vec[m1],"rho=",rho.vec[m2])
c(lambda.vec[m1], rho.vec[m2], sum(bic.vec),
round(c(sum(B0.array != 0 & B_sep.array != 0)/sum(B0.array != 0),
sum(B0.array == 0 & B_sep.array == 0)/sum(B0.array == 0),
sqrt(sum((B0.array - B_sep.array)^2)/sum(B0.array^2)),
sum(Theta0.array != 0 & Theta_sep.array != 0)/sum(Theta0.array != 0),
sum(Theta0.array == 0 & Theta_sep.array == 0)/sum(Theta0.array == 0),
sqrt(sum((Theta0.array - Theta_sep.array)^2)/sum(Theta0.array^2))), 3))
}
eval.mat1 = lapply(1:nlambda*nrho, loopfun1)
for(m3 in 1:nlambda*nrho){cat(floor((m3-1)/nrho) + 1,m3 %% nrho)}
for(m3 in 1:nlambda*nrho){c(floor((m3-1)/nrho),1,m3 %% nrho)}
c(floor((m3-1)/nrho),1,m3 %% nrho)
c(floor((m3-1)/nrho),m3 %% nrho)
m3
c(floor((m3-1)/nrho)+1,m3 %% nrho)
m2 = m3 - m1*nrho
