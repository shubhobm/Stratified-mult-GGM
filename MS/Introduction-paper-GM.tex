\section{Introduction}

Aberrations in complex biological systems develop in the background of diverse genetic and environmental factors and are associated with multiple complex molecular events. These include changes in the genome, transcriptome, proteome and metabolome, as well as epigenetic effects. Advances in high-throughput profiling techniques have enabled a systematic and comprehensive exploration of the genetic and epigenetic basis of various diseases, including cancer \citep{lee2016integrated, kaushik2016inhibition}, diabetes \citep{yuan2014integrated,sas2018shared}, chronic kidney disease \citep{atzler2014integrated}, etc. Further, such multi-Omics collections have become available for patients belonging to different, but related disease subtypes, with The Cancer Genome Atlas (TCGA: \cite{Tomczak15}) being a prototypical one. Hence, there is an increasing need for models that can {\em integrate} such complex data both {\em vertically} across multiple modalities and {\em horizontally} across different disease subtypes.

Figure~\ref{fig:multi2layer} provides a schematic representation of the horizontal and vertical structure of such heterogeneous multi-modal Omics data as outlined above. A simultaneous analysis of all components in this complex layered structure has been coined in the literature as {\it data integration}. While it is common knowledge that this will result in a more comprehensive picture of the regulatory mechanisms behind diseases, phenotypes and biological processes in general, there is a dearth of rigorous methodologies that satisfactorily tackle all challenges that stem from attempts to perform data integration \citep{GomezCabreroEtal14,JoycePalsson06,GligPrzulj15}. A review of the present approaches towards achieving this goal, which are based mostly on specific case studies, can be found in \cite{GligPrzulj15} and \cite{ZhangOuyangZhao17}.

\paragraph{}
Gaussian Graphical Models (GGM) have been extensively used to model biological networks in the last few years. While the initial work on GGMs focused on estimating undirected edges within a single network through obtaining sparse estimates of the inverse covariance matrix from high-dimensional data (e.g. see the references in \cite{BuhlmannvandeGeer11}), attention has shifted to estimating parameters from more complex structures, including multiple related graphical models and hierarchical multilayer models comprising of both directed and undirected edges. For the first class of problems, \cite{GuoEtal11} and \cite{XieLiuValdar16} assumed perturbations over a common underlying structure to model multiple precision matrices, while \cite{DanaherEtal14} proposed using fused/group lasso type penalties for the same task. To incorporate prior information on the group structures across several graphs, \cite{MaMichailidis15} proposed the Joint Structural Estimation Method (JSEM), which uses group-penalized neighborhood regression and subsequent refitting for estimating precision matrices.
For the second problem, a two-layered structure can be modeled by interpreting directed edges between the two layers as elements of a multitask regression coefficient matrix, while undirected edges inside either layer correspond to the precision matrix of predictors in that layer. While several methods exist in the literature for joint estimation of both parameters \citep{LeeLiu12, CaiEtal12}, only recently \cite{LinEtal16} made the observation that a multi-layer model can, in fact, be decomposed into a series of two-layer problems. Subsequently, they proposed an estimation algorithm and derived theoretical properties of the resulting estimators.

\begin{figure}
\centering
\includegraphics[]{multi2layer}
\caption{Multiple multilayer graphical models. The matrices $(\bfX^k, \bfY^k, \bfZ^k), k = 1,2,3$ indicate data for each layer and category $k$. Within-layer connections (black lines) are undirected, while between-layer connections (red lines) go from an upper layer to the successive lower layer. For each type of edges (i.e. within $\cX, \cY, \cZ$ and $\cX \rightarrow \cY, \cY \rightarrow \cZ$), there are common edges across some or all $k$. }
\label{fig:multi2layer}
\end{figure}

\paragraph{}
All the above approaches focus either on the horizontal or the vertical dimensions in the full hierarchical structure depicted in Figure~\ref{fig:multi2layer}. Hence, multiple related groups of heterogeneous data sets has to be modeled by analyzing all data in individual layers (i.e. models for $\{ \bfX^k \}$, $\{ \bfY^k \}$, $\{ \bfZ^k \}$), and then separately analyzing individual hierarchies of datasets (i.e. separate models for $(\bfX^k, \bfY^k, \bfZ^k), k = 1,2,3$). Although a recent paper \citep{ZhangOuyangZhao17} provides a model for the full structure in Figure~\ref{fig:multi2layer} using penalized log-likelihoods, they do not give theoretical guarantees for the estimates, and limit the numerical examples to small feature dimensions ($<70$) only. Thus, a truly rigorous and scalable model for data integration is yet to be proposed. SUBHO THIS PAPER DOES NOT DISTNIGUISH BETWEEN HIERARCHIES AND HENCE IT IS DIFFICULT TO DELINEATE WHO IMPACTS WHOM AND
ALSO THAT MAKES THE PARAMETER SPACE TO EXPLODE. FOR A MORE BIOLOGICAL EXAMPLE SEE ALSO https://academic.oup.com/nar/article/43/15/e98/2414280. On the other hand, our structure assumes no feedback which somebody could criticize.
So, we need to explain the nuances and say pros and cons.

While there has been some progress for parameter estimation in multilayer models, little is known about the sampling distributions of resulting estimates. Current research on such distributions and related testing procedures for estimates from high-dimensional problems has been limited to single-response regression using lasso \citep{ZhangZhang14,JavanmardMontanari14,JavanmardMontanari18,vanDeGeerEtal14} or group lasso \citep{MitraZhang16} penalties, and partial correlations of single \citep{CaiLiu16} or multiple \citep{BelilovskyEtal16,Liu17} GGMs. From a systemic perspective, testing and identifying downstream interactions that differ across experimental conditions or disease subtypes can offer important insights on the underlying biological process \citep{MaoEtal17,LiEtal15}. In the proposed integrative framework, this can be accomplished by developing a hypothesis testing procedure for entries in the within-layer regression matrices.

\paragraph{}
The contributions of this paper are two-fold. Firstly, we propose an integrative framework to conduct simultaneous inference for all parameters in multiple multilayer graphical models, essentially formalizing the structure in Figure~\ref{fig:multi2layer}. We decompose the multi-layer problem into a series of two-layer problems, incorporate prior information on structural dependencies through imposing group structures on the model parameters, propose an estimation algorithm for them and derive theoretical properties of the estimators. Secondly, we obtain {\em debiased} versions of within-layer regression coefficients in this two-layer model, and derive their asymptotic distributions using estimates of model parameters that satisfy generic convergence guarantees. Consequently, we formulate a global test, as well as a simultaneous testing procedure that controls for False Discovery Rate (FDR) to detect important pairwise differences among directed edges between layers.

Our proposed framework for knowledge discovery from heterogeneous data sources is highly flexible. The group sparsity assumptions in our estimation technique can be replaced by other structural restrictions, for example low-rank or low-rank-plus-sparse, as and when deemed appropriate by the prior dependency assumptions across parameters. As long as the resulting estimates converge to corresponding true parameters at certain rates, they can be used by the developed testing methodology.

\paragraph{Organization of paper.}
We start with the model formulation in Section~\ref{sec:sec2}, then introduce our computational algorithm for a two-layer model, and derive theoretical convergence properties of the algorithm and resulting estimates. In section~\ref{sec:sec3}, we start by introducing the debiased versions of rows of the regression coefficient matrix estimates in our model, then use already computed parameter estimates that satisfy some general consistency conditions to obtain its asymptotic distribution. We then move on to pairwise testing, and use sparse estimates from our algorithm to propose a global test to detect overall differences in rows of the coefficient matrices, as well as a multiple testing procedure to detect elementwise differences and perform within-row thresholding of estimates in presence of moderate misspecification of the group sparsity structure. Section~\ref{sec:sec4} is devoted to implementation of our methodology. We evaluate the performance of our estimation and testing procedure through several simulation settings, and give strategies to speed up the computational algorithm for high data dimensions.  We conclude the paper with a discussion in Section~\ref{sec:sec5}. Proofs of all theoretical results, as well as some auxiliary results, are given in the appendix.

\paragraph{Notations.}
We denote scalars by small letters, vectors by bold small letters and matrices by bold capital letters. For any matrix $\bfA$, $(\bfA)_{ij}$ denote its element in the $(i,j)\Th$ position. For $a,b \in \BN$, we denote the set of all $a \times b$ real matrices by $\BM(a,b)$. For a positive semi-definite matrix $\bfP$, we denote its smallest and largest eigenvalues by $\Lambda_{\min} (\bfP)$ and $\Lambda_{\max} (\bfP)$, respectively. For any positive integer $c$, define $\cI_c = \{ 1, \ldots, c\}$. For vectors $\bfv$ and matrices $\bfM$, $\| \bfv \|$, $\|\bfv \|_1$ or $\|\bfM \|_1$ and $\|\bfv \|_\infty$ or $\|\bfM \|_\infty$ denote euclidean, $\ell_1$ and $\ell_\infty$ norms, respectively. The notation $\supp(\bfA)$ indicates the non-zero edge set in a matrix (or vector) $\bfA$, i.e. $\supp(\bfA) = \{(i,j): (\bfA)_{ij} \neq 0\}$. For positive real numbers $A, B$ we write $A \succsim B$ if there exists $c>0$ independent of model parameters such that $A \geq cB$. We use the `$:=$' notation to define a quantity for the first time.